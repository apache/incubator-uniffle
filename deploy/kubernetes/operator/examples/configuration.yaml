#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

---
kind: ConfigMap
apiVersion: v1
metadata:
  name: rss-configuration
  namespace: kube-system
data:
  coordinator.conf: |-
    rss.coordinator.app.expired 60000
    rss.coordinator.exclude.nodes.file.path /data/rssadmin/rss/coo
    rss.coordinator.server.heartbeat.timeout 30000
    rss.jetty.http.port 19996
    rss.rpc.server.port 19997
    # rss.security.hadoop.kerberos.keytab.file /data/rssadmin/hadoop/conf/uniffle.keytab
  log4j2.xml: |-
    <?xml version="1.0" encoding="UTF-8"?>
    <Configuration status="WARN" monitorInterval="30">
        <Appenders>
            <Console name="console" target="SYSTEM_ERR">
                <PatternLayout pattern="[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%t] [%p] %c{1}.%M - %m%n%ex"/>
            </Console>
            <RollingFile name="RollingAppender" fileName="${sys:log.path}" filePattern="${sys:log.path}.%i">
                <PatternLayout pattern="[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%t] [%p] %c{1}.%M - %m%n%ex"/>
                    <Policies>
                        <SizeBasedTriggeringPolicy size="2GB"/>
                    </Policies>
                    <DefaultRolloverStrategy max="10"/>
            </RollingFile>
        </Appenders>
        <Loggers>
            <Root level="info">
                <AppenderRef ref="console"/>
                <AppenderRef ref="RollingAppender"/>
            </Root>
            <Logger name="io.grpc.netty.shaded.io.grpc.netty" level="info" additivity="false">
                <AppenderRef ref="console"/>
                <AppenderRef ref="RollingAppender"/>
            </Logger>
            <Logger name="org.apache.hadoop" level="info" additivity="false">
                <AppenderRef ref="console"/>
                <AppenderRef ref="RollingAppender"/>
            </Logger>
            <Logger name="org.eclipse.jetty" level="info" additivity="false">
                <AppenderRef ref="console"/>
                <AppenderRef ref="RollingAppender"/>
            </Logger>
        </Loggers>
    </Configuration>
  server.conf: |-
    # these configurations in comments are generated by operator automatically
    # rss.coordinator.quorum
    # rss.jetty.http.port
    # rss.rpc.server.port
    # rss.storage.basePath
    rss.rpc.executor.size 500
    rss.rpc.message.max.size 1073741824
    rss.server.app.expired.withoutHeartbeat 120000
    rss.server.buffer.capacity 60g
    rss.server.commit.timeout 600000
    rss.server.disk.capacity 3g
    rss.server.event.size.threshold.l1 128m
    rss.server.event.size.threshold.l2 192m
    rss.server.event.size.threshold.l3 256m
    rss.server.flush.cold.storage.threshold.size 128m
    rss.server.flush.thread.alive 6
    rss.server.flush.localfile.threadPool.size 12
    rss.server.flush.hadoop.threadPool.size 60
    rss.server.hadoop.dfs.client.socket-timeout 15000
    rss.server.hadoop.dfs.replication 2
    rss.server.hdfs.base.path hdfs://${your-hdfs-path}
    rss.server.health.check.enable false
    rss.server.heartbeat.interval 10000
    rss.server.memory.shuffle.highWaterMark.percentage 70.0
    rss.server.memory.shuffle.lowWaterMark.percentage 10.0
    rss.server.pending.event.timeoutSec 600
    rss.server.preAllocation.expired 120000
    rss.server.read.buffer.capacity 5g
    rss.server.shuffle.expired.timeout.ms 120000
    rss.server.write.retry.max 2
    rss.storage.type MEMORY_LOCALFILE
    # rss.security.hadoop.kerberos.keytab.file /data/rssadmin/hadoop/conf/uniffle.keytab
  dynamic_client.conf: |-
    # MEMORY_LOCALFILE_HDFS is recommended for production environment
    rss.storage.type MEMORY_LOCALFILE_HDFS
    # multiple remote storages are supported, and client will get assignment from coordinator
    rss.coordinator.remote.storage.path hdfs://cluster1/path,hdfs://cluster2/path
    rss.writer.require.memory.retryMax 1200
    rss.client.retry.max 50
    rss.writer.send.check.timeout 600000
    rss.client.read.buffer.size 14m
  rss-env.sh: |-
    set -o pipefail
    set -o nounset
    set -o errexit
    HADOOP_HOME="/data/rssadmin/hadoop"
    RUNNER="${JAVA_HOME}/bin/java"
    JPS="${JAVA_HOME}/bin/jps"
    
    # HADOOP_CONF_DIR, Hadoop configuration directory (Default: ${HADOOP_HOME}/etc/hadoop)
    HADOOP_CONF_DIR="/data/rssadmin/hadoop/conf"

    # RSS_HOME, RSS home directory (Default: parent directory of the script)
    # RSS_CONF_DIR, RSS configuration directory (Default: ${RSS_HOME}/conf)
    # RSS_PID_DIR, Where the pid file is stored (Default: ${RSS_HOME})
    # RSS_LOG_DIR, Where log files are stored (Default: ${RSS_HOME}/logs)
    # RSS_IP, IP address Shuffle Server binds to on this node (Default: first non-loopback ipv4)
